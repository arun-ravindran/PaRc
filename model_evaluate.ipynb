{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Modeling\n",
    "\n",
    "Generate train, validation, and test torch data sets by cleaning text, and retaining only English words.\n",
    "Implement Manhattan distance based LSTM (MaLSTM) bug patch similarity scoring model\n",
    "Train and evaluate model\n",
    "\n",
    "Step 4: Evaluation\n",
    "\n",
    "For a testbug, create a dataset with all patches. Calculate the MaLSTM score for all patches. Find the rank of the matching patching patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torchtext to construct training, validation, and test dataset \n",
    "import torch\n",
    "from torchtext import data\n",
    "import spacy\n",
    "\n",
    "\n",
    "import enchant\n",
    "en_dict = enchant.Dict(\"en_US\")\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Tokenize and filter non-English words and stop words\n",
    "def tokenizer(text):\n",
    "    english_text =  \" \"\n",
    "    for word in text.split():\n",
    "        if en_dict.check(word):\n",
    "            english_text = english_text + word + \" \"\n",
    "    return[token.text for token in spacy_nlp(english_text) if not token.is_stop and token.text != \" \"] # filter stop words\n",
    "\n",
    "\n",
    "BUGTITLE = data.Field(sequential=True, tokenize=tokenizer, lower=True)\n",
    "PATCH = data.Field(sequential=True, tokenize=tokenizer, lower=True)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "\n",
    "fields = {'bugtitle': ('b', BUGTITLE), 'patch': ('p', PATCH), 'label': ('l', LABEL)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                    path = './',\n",
    "                    train = 'bugpatchlabel_tr.json', \n",
    "                    validation = 'bugpatchlabel_val.json', \n",
    "                    test = 'bugpatchlabel_tst.json',\n",
    "                    format = 'json',\n",
    "                    fields = fields\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(vars(train_data[0]))\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(vars(valid_data[0]))\n",
    "print(f'Number of test examples: {len(test_data)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeddding with Glove - 862 MB takes time to download for the first time!\n",
    "BUGTITLE.build_vocab(train_data.b, max_size=25000, min_freq=1, vectors=\"glove.6B.100d\")\n",
    "print(len(BUGTITLE.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH.build_vocab(train_data.p, max_size=25000, min_freq=1, vectors=\"glove.6B.100d\")\n",
    "print(len(PATCH.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over trainig and validation data in batches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size= BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.b),\n",
    "    sort_within_batch=False,\n",
    "    device=device)\n",
    "\n",
    "a = next(iter(train_iterator)); vars(a).keys()\n",
    "b = next(iter(valid_iterator)); vars(b).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class SiameseLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        embedded1 = self.dropout(self.embedding(x1))\n",
    "        embedded2 = self.dropout(self.embedding(x2))\n",
    "         \n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        output1, (hidden1, cell1) = self.rnn(embedded1)\n",
    "        output2, (hidden2, cell2) = self.rnn(embedded2)\n",
    "              \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden1 = self.dropout(torch.cat((hidden1[-2,:,:], hidden1[-1,:,:]), dim=1))\n",
    "        hidden2 = self.dropout(torch.cat((hidden2[-2,:,:], hidden2[-1,:,:]), dim=1))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        self.encoding1 = hidden1.squeeze(0)\n",
    "        self.encoding2 = hidden2.squeeze(0)\n",
    "        \n",
    "         # Obtain similarity score predictions by calculating the negative exponenet of the Manhattan distance between sentence encodings\n",
    "            \n",
    "        return torch.exp(-torch.norm((self.encoding1 - self.encoding2), 1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "INPUT_DIM = len(PATCH.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "CLIP = 1.25\n",
    "\n",
    "\n",
    "model = SiameseLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "\n",
    "pretrained_embeddings = PATCH.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train routine \n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \n",
    "    rounded_preds = torch.round(preds)\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:        \n",
    "        optimizer.zero_grad()            \n",
    "        predictions = model(batch.b, batch.p)\n",
    "        loss = criterion(predictions, batch.l)\n",
    "        acc = binary_accuracy(predictions, batch.l)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), CLIP) # Clip gradients\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalaute routine\n",
    "def evaluate(model, iterator, criterion, printpreds=False):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.b, batch.p)\n",
    "            if (printpreds == True) : print(torch.round(predictions))\n",
    "            loss = criterion(predictions, batch.l)\n",
    "            acc = binary_accuracy(predictions, batch.l)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evalaute model\n",
    "import time\n",
    "\n",
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        #torch.save(model, 'model.pt')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time to compute: {(end - start)/60} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "#model = torch.load('model.pt')\n",
    "#model.eval()\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate model by determining rank of a test bug ####33\n",
    "\n",
    "# Obtain index of testbug in the original bugpatch dataset\n",
    "import json\n",
    "\n",
    "patch = [] # List of patches\n",
    "bug = [] # List of all bugs\n",
    "testbug = [] # List of test bug indexes\n",
    "\n",
    "with open(\"bugpatch.json\", \"r\") as fp:\n",
    "    bpdata = json.load(fp)\n",
    "\n",
    "for k,v in bpdata.items():\n",
    "    bug.append(k)\n",
    "    patch.append(v)\n",
    "    \n",
    "\n",
    "with open('testindex.txt', 'r', encoding=\"utf-8\") as fp: # testindex.txt in Step 2: datagen.py\n",
    "    for line in fp.readlines():\n",
    "        testbug.append(int(line))\n",
    "\n",
    "print(bug[testbug[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a json file of test bug and all patches\n",
    "bugidx = testbug[0]\n",
    "print(bugidx) # Note: Bug index is the same as the matching patch index\n",
    "print(bug[bugidx])\n",
    "#print(patch[bugidx])\n",
    "d = []\n",
    "for p in patch:\n",
    "    d.append({\"bugtitle\":bug[bugidx], \"patch\":p, \"label\":0})\n",
    "\n",
    "print(len(d))\n",
    "with open('bugpatchlabel_eval.json', 'w+', encoding=\"utf-8\") as fp:\n",
    "    for ele in d:\n",
    "        json.dump(ele, fp)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and iterator\n",
    "eval_data = data.TabularDataset(\n",
    "                    path = './bugpatchlabel_eval.json',\n",
    "                    format = 'json',\n",
    "                    fields = fields\n",
    ")\n",
    "\n",
    "eval_iterator = data.BucketIterator(\n",
    "    eval_data, \n",
    "    batch_size= BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.b),\n",
    "    sort_within_batch=False,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = np.array([0])\n",
    "with torch.no_grad():\n",
    "    for batch in eval_iterator:\n",
    "        preds = model(batch.b, batch.p)\n",
    "        predictions = np.append(predictions, preds.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))\n",
    "order = predictions.argsort()\n",
    "ranks = order.argsort()\n",
    "print(ranks[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
